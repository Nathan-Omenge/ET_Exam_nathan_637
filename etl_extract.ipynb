{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff2ad7e",
   "metadata": {},
   "source": [
    "# Data Extraction   \n",
    "---\n",
    "# 1. Introduction\n",
    "\n",
    "Here, I demonstrate the **Extract (E)** phase of the ETL process.  \n",
    "The purpose of this step is to **load, inspect, and validate** the *Airline Tweets dataset*, which contains customer feedback directed at major airlines on Twitter(X).\n",
    "\n",
    "This extraction process ensures that the data is **properly understood**, **well structured**, and **ready for transformation and analysis** (as detailed later in *etl_transform.ipynb*).  \n",
    "\n",
    "### Tasks Performed\n",
    "1. Loading both the **raw dataset** (`raw_data.csv`) and the **incremental dataset** (`incremental_data.csv`) from the `data/` directory.  \n",
    "2. Performing exploratory data analysis to understand the datasetsâ€™ structure and characteristics.  \n",
    "3. Identifying and documenting key data quality issues such as missing values, duplicates, and inconsistent types.  \n",
    "4. Validating and ensuring column consistency between both datasets.  \n",
    "5. Confirm readiness for transformation by verifying schema alignment and documenting observations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c003da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1056330",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Loading the Raw and Prepared Incremental Dataset  \n",
    "\n",
    "I now load both the **raw** and **incremental** datasets, perform exploratory checks, and identify data quality issues such as missing values, duplicates, and inconsistent data types.  \n",
    "The objective is to ensure both datasets are clean, structurally consistent, and ready for integration during the transformation stage. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c1c3a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory verified at: /Users/nathanomenge/Desktop/ET_Exam_Nathan_637/data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have littl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence negativereason  negativereason_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000            NaN                        NaN   \n",
       "1  570301130888122368          positive                        0.3486            NaN                     0.0000   \n",
       "2  570301083672813571           neutral                        0.6837            NaN                        NaN   \n",
       "3  570301031407624196          negative                        1.0000     Bad Flight                     0.7033   \n",
       "4  570300817074462722          negative                        1.0000     Can't Tell                     1.0000   \n",
       "\n",
       "          airline airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0  Virgin America                    NaN     cairdin                 NaN              0   \n",
       "1  Virgin America                    NaN    jnardino                 NaN              0   \n",
       "2  Virgin America                    NaN  yvonnalynn                 NaN              0   \n",
       "3  Virgin America                    NaN    jnardino                 NaN              0   \n",
       "4  Virgin America                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                                                                                      text  \\\n",
       "0                                                                                      @VirginAmerica What @dhepburn said.   \n",
       "1                                                 @VirginAmerica plus you've added commercials to the experience... tacky.   \n",
       "2                                                  @VirginAmerica I didn't today... Must mean I need to take another trip!   \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have littl...   \n",
       "4                                                                  @VirginAmerica and it's a really big bad thing about it   \n",
       "\n",
       "  tweet_coord              tweet_created tweet_location               user_timezone  \n",
       "0         NaN  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1         NaN  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2         NaN  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3         NaN  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4         NaN  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the data directory exists\n",
    "base_dir = os.getcwd()\n",
    "data_dir = os.path.join(base_dir, \"data\")\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "print(\"Data directory verified at:\", data_dir)\n",
    "\n",
    "# Preview the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768a5f04",
   "metadata": {},
   "source": [
    "### Load Datasets\n",
    "\n",
    "I now load both the **raw dataset (`raw_data.csv`)** and the **incremental dataset (`incremental_data.csv`)** into Pandas DataFrames.\n",
    "\n",
    "The raw dataset contains the original airline tweets, while the incremental dataset subsets the raw dataset to simulate newly acquired tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2aed144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental dataset created and saved at: /Users/nathanomenge/Desktop/ET_Exam_Nathan_637/data/incremental_data.csv\n",
      "Incremental dataset shape: (2000, 15)\n",
      "\n",
      "--- RAW DATA PREVIEW ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52-08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59-08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48-08:00</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence negativereason  negativereason_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000            NaN                        NaN   \n",
       "1  570301130888122368          positive                        0.3486            NaN                        0.0   \n",
       "2  570301083672813571           neutral                        0.6837            NaN                        NaN   \n",
       "\n",
       "          airline airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0  Virgin America                    NaN     cairdin                 NaN              0   \n",
       "1  Virgin America                    NaN    jnardino                 NaN              0   \n",
       "2  Virgin America                    NaN  yvonnalynn                 NaN              0   \n",
       "\n",
       "                                                                       text tweet_coord             tweet_created  \\\n",
       "0                                       @VirginAmerica What @dhepburn said.         NaN 2015-02-24 11:35:52-08:00   \n",
       "1  @VirginAmerica plus you've added commercials to the experience... tacky.         NaN 2015-02-24 11:15:59-08:00   \n",
       "2   @VirginAmerica I didn't today... Must mean I need to take another trip!         NaN 2015-02-24 11:15:48-08:00   \n",
       "\n",
       "  tweet_location               user_timezone  \n",
       "0            NaN  Eastern Time (US & Canada)  \n",
       "1            NaN  Pacific Time (US & Canada)  \n",
       "2      Lets Play  Central Time (US & Canada)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- INCREMENTAL DATA PREVIEW ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8966</th>\n",
       "      <td>570310600460525568</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6292</td>\n",
       "      <td>Flight Booking Problems</td>\n",
       "      <td>0.3146</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jhazelnut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways  is there a better time to call? My flight is on Friday and I need to change it. Worried I may be on hold...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:53:37-08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8967</th>\n",
       "      <td>570310144459972608</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GAKotsch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways and when will one of these agents be available to speak?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:51:48-08:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6746</th>\n",
       "      <td>570309345281486848</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jaxbra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue Yesterday on my way from EWR to FLL just after take-off. :)\\n#wheelsup #JetBlueSoFly http://t.co/9xkiy0Kq2j</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:48:38-08:00</td>\n",
       "      <td>east brunswick, nj</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id airline_sentiment  airline_sentiment_confidence           negativereason  \\\n",
       "8966  570310600460525568          negative                        0.6292  Flight Booking Problems   \n",
       "8967  570310144459972608          negative                        1.0000   Customer Service Issue   \n",
       "6746  570309345281486848          positive                        0.6469                      NaN   \n",
       "\n",
       "      negativereason_confidence     airline airline_sentiment_gold       name negativereason_gold  retweet_count  \\\n",
       "8966                     0.3146  US Airways                    NaN  jhazelnut                 NaN              0   \n",
       "8967                     1.0000  US Airways                    NaN   GAKotsch                 NaN              0   \n",
       "6746                        NaN       Delta                    NaN     jaxbra                 NaN              0   \n",
       "\n",
       "                                                                                                                         text  \\\n",
       "8966  @USAirways  is there a better time to call? My flight is on Friday and I need to change it. Worried I may be on hold...   \n",
       "8967                                                      @USAirways and when will one of these agents be available to speak?   \n",
       "6746     @JetBlue Yesterday on my way from EWR to FLL just after take-off. :)\\n#wheelsup #JetBlueSoFly http://t.co/9xkiy0Kq2j   \n",
       "\n",
       "     tweet_coord             tweet_created      tweet_location           user_timezone  \n",
       "8966         NaN 2015-02-24 11:53:37-08:00                 NaN                     NaN  \n",
       "8967         NaN 2015-02-24 11:51:48-08:00                 NaN  Atlantic Time (Canada)  \n",
       "6746         NaN 2015-02-24 11:48:38-08:00  east brunswick, nj  Atlantic Time (Canada)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define dataset paths\n",
    "raw_data_path = os.path.join(data_dir, \"raw_data.csv\")\n",
    "incremental_data_path = os.path.join(data_dir, \"incremental_data.csv\")\n",
    "\n",
    "# Subsetting Raw dataset to Create Incremental Dataset\n",
    "# Convert tweet_created to datetime for sorting\n",
    "df_raw[\"tweet_created\"] = pd.to_datetime(df_raw[\"tweet_created\"], errors=\"coerce\")\n",
    "\n",
    "# Subset the most recent 2000 records to simulate new incremental data\n",
    "df_incremental = (\n",
    "    df_raw.sort_values(\"tweet_created\", ascending=False)\n",
    "          .head(2000)\n",
    "          .copy()\n",
    ")\n",
    "\n",
    "# Save the incremental dataset\n",
    "incremental_data_path = os.path.join(data_dir, \"incremental_data.csv\")\n",
    "df_incremental.to_csv(incremental_data_path, index=False)\n",
    "\n",
    "print(f\"Incremental dataset created and saved at: {incremental_data_path}\")\n",
    "print(f\"Incremental dataset shape: {df_incremental.shape}\")\n",
    "\n",
    "\n",
    "# Visual confirmation of dataset similarity\n",
    "print(\"\\n--- RAW DATA PREVIEW ---\")\n",
    "display(df_raw.head(3))\n",
    "\n",
    "print(\"\\n--- INCREMENTAL DATA PREVIEW ---\")\n",
    "display(df_incremental.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27e7bcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RAW DATASET STRUCTURE ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype                    \n",
      "---  ------                        --------------  -----                    \n",
      " 0   tweet_id                      14640 non-null  int64                    \n",
      " 1   airline_sentiment             14640 non-null  object                   \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64                  \n",
      " 3   negativereason                9178 non-null   object                   \n",
      " 4   negativereason_confidence     10522 non-null  float64                  \n",
      " 5   airline                       14640 non-null  object                   \n",
      " 6   airline_sentiment_gold        40 non-null     object                   \n",
      " 7   name                          14640 non-null  object                   \n",
      " 8   negativereason_gold           32 non-null     object                   \n",
      " 9   retweet_count                 14640 non-null  int64                    \n",
      " 10  text                          14640 non-null  object                   \n",
      " 11  tweet_coord                   1019 non-null   object                   \n",
      " 12  tweet_created                 14640 non-null  datetime64[ns, UTC-08:00]\n",
      " 13  tweet_location                9907 non-null   object                   \n",
      " 14  user_timezone                 9820 non-null   object                   \n",
      "dtypes: datetime64[ns, UTC-08:00](1), float64(2), int64(2), object(10)\n",
      "memory usage: 1.7+ MB\n",
      "\n",
      "--- INCREMENTAL DATASET STRUCTURE ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2000 entries, 8966 to 12776\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype                    \n",
      "---  ------                        --------------  -----                    \n",
      " 0   tweet_id                      2000 non-null   int64                    \n",
      " 1   airline_sentiment             2000 non-null   object                   \n",
      " 2   airline_sentiment_confidence  2000 non-null   float64                  \n",
      " 3   negativereason                1209 non-null   object                   \n",
      " 4   negativereason_confidence     1411 non-null   float64                  \n",
      " 5   airline                       2000 non-null   object                   \n",
      " 6   airline_sentiment_gold        5 non-null      object                   \n",
      " 7   name                          2000 non-null   object                   \n",
      " 8   negativereason_gold           3 non-null      object                   \n",
      " 9   retweet_count                 2000 non-null   int64                    \n",
      " 10  text                          2000 non-null   object                   \n",
      " 11  tweet_coord                   123 non-null    object                   \n",
      " 12  tweet_created                 2000 non-null   datetime64[ns, UTC-08:00]\n",
      " 13  tweet_location                1274 non-null   object                   \n",
      " 14  user_timezone                 1307 non-null   object                   \n",
      "dtypes: datetime64[ns, UTC-08:00](1), float64(2), int64(2), object(10)\n",
      "memory usage: 250.0+ KB\n",
      "\n",
      "--- RAW DATASET SUMMARY STATISTICS ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.464000e+04</td>\n",
       "      <td>14640.000000</td>\n",
       "      <td>10522.000000</td>\n",
       "      <td>14640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.692184e+17</td>\n",
       "      <td>0.900169</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.082650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.791112e+14</td>\n",
       "      <td>0.162830</td>\n",
       "      <td>0.330440</td>\n",
       "      <td>0.745778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.675883e+17</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.685592e+17</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.694779e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.698905e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.703106e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id  airline_sentiment_confidence  negativereason_confidence  retweet_count\n",
       "count  1.464000e+04                  14640.000000               10522.000000   14640.000000\n",
       "mean   5.692184e+17                      0.900169                   0.638298       0.082650\n",
       "std    7.791112e+14                      0.162830                   0.330440       0.745778\n",
       "min    5.675883e+17                      0.335000                   0.000000       0.000000\n",
       "25%    5.685592e+17                      0.692300                   0.360600       0.000000\n",
       "50%    5.694779e+17                      1.000000                   0.670600       0.000000\n",
       "75%    5.698905e+17                      1.000000                   1.000000       0.000000\n",
       "max    5.703106e+17                      1.000000                   1.000000      44.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- INCREMENTAL DATASET SUMMARY STATISTICS ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1411.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.701924e+17</td>\n",
       "      <td>0.891243</td>\n",
       "      <td>0.618679</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.219932e+13</td>\n",
       "      <td>0.166962</td>\n",
       "      <td>0.338251</td>\n",
       "      <td>0.355617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.700283e+17</td>\n",
       "      <td>0.336800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.700922e+17</td>\n",
       "      <td>0.685475</td>\n",
       "      <td>0.354450</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.702232e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.702741e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.703106e+17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id  airline_sentiment_confidence  negativereason_confidence  retweet_count\n",
       "count  2.000000e+03                   2000.000000                1411.000000    2000.000000\n",
       "mean   5.701924e+17                      0.891243                   0.618679       0.060000\n",
       "std    9.219932e+13                      0.166962                   0.338251       0.355617\n",
       "min    5.700283e+17                      0.336800                   0.000000       0.000000\n",
       "25%    5.700922e+17                      0.685475                   0.354450       0.000000\n",
       "50%    5.702232e+17                      1.000000                   0.666700       0.000000\n",
       "75%    5.702741e+17                      1.000000                   1.000000       0.000000\n",
       "max    5.703106e+17                      1.000000                   1.000000       5.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- STRUCTURAL OVERVIEW OF BOTH DATASETS ---\n",
    "\n",
    "print(\"\\n--- RAW DATASET STRUCTURE ---\")\n",
    "df_raw.info()\n",
    "\n",
    "print(\"\\n--- INCREMENTAL DATASET STRUCTURE ---\")\n",
    "df_incremental.info()\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "print(\"\\n--- RAW DATASET SUMMARY STATISTICS ---\")\n",
    "display(df_raw.describe())\n",
    "\n",
    "print(\"\\n--- INCREMENTAL DATASET SUMMARY STATISTICS ---\")\n",
    "display(df_incremental.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d325c170",
   "metadata": {},
   "source": [
    "### 3. Structural Overview Discussion\n",
    "\n",
    "Both the **raw dataset** (`raw_data.csv`) and the **incremental dataset** (`incremental_data.csv`) contain **15 columns** with matching names, order, and data types.  \n",
    "\n",
    "The columns represent tweet metadata, sentiment classification, and contextual information:\n",
    "- **Identifiers and metadata:** `tweet_id`, `tweet_created`, `retweet_count`\n",
    "- **Sentiment information:** `airline_sentiment`, `airline_sentiment_confidence`, `negativereason`, `negativereason_confidence`\n",
    "- **Categorical and descriptive characteristics:** `airline`, `name`, `user_timezone`, and `tweet_location`\n",
    "\n",
    "**Key Observations**\n",
    "1. Both datasets maintain consistent data types â€” categorical fields stored as `object`, numerical metrics as `float64` or `int64`, and the timestamp column (`tweet_created`) correctly parsed as `datetime64[ns]`.  \n",
    "2. Summary statistics show similar ranges and distributions for numeric fields such as `airline_sentiment_confidence`, `negativereason_confidence`, and `retweet_count`, confirming statistical consistency between the two datasets.  \n",
    "3. The incremental dataset (2,000 records) is a chronologically recent subset of the raw data, preserving the same schema and integrity needed for downstream ETL transformation.  \n",
    "\n",
    "This confirms that both datasets are now **ready for quality inspection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e669a0",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c38ddd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MISSING VALUES (RAW DATASET) ===\n",
      "\n",
      "negativereason                5462\n",
      "negativereason_confidence     4118\n",
      "airline_sentiment_gold       14600\n",
      "negativereason_gold          14608\n",
      "tweet_coord                  13621\n",
      "tweet_location                4733\n",
      "user_timezone                 4820\n",
      "dtype: int64\n",
      "\n",
      "=== MISSING VALUES (INCREMENTAL DATASET) ===\n",
      "\n",
      "negativereason                791\n",
      "negativereason_confidence     589\n",
      "airline_sentiment_gold       1995\n",
      "negativereason_gold          1997\n",
      "tweet_coord                  1877\n",
      "tweet_location                726\n",
      "user_timezone                 693\n",
      "dtype: int64\n",
      "\n",
      "=== DUPLICATE RECORDS ===\n",
      "Raw dataset duplicate records: 36\n",
      "Incremental dataset duplicate records: 36\n",
      "\n",
      "=== DATA TYPE CONSISTENCY ===\n",
      "RAW dataset types:\n",
      " tweet_id                                            int64\n",
      "airline_sentiment                                  object\n",
      "airline_sentiment_confidence                      float64\n",
      "negativereason                                     object\n",
      "negativereason_confidence                         float64\n",
      "airline                                            object\n",
      "airline_sentiment_gold                             object\n",
      "name                                               object\n",
      "negativereason_gold                                object\n",
      "retweet_count                                       int64\n",
      "text                                               object\n",
      "tweet_coord                                        object\n",
      "tweet_created                   datetime64[ns, UTC-08:00]\n",
      "tweet_location                                     object\n",
      "user_timezone                                      object\n",
      "dtype: object\n",
      "\n",
      "INCREMENTAL dataset types:\n",
      " tweet_id                                            int64\n",
      "airline_sentiment                                  object\n",
      "airline_sentiment_confidence                      float64\n",
      "negativereason                                     object\n",
      "negativereason_confidence                         float64\n",
      "airline                                            object\n",
      "airline_sentiment_gold                             object\n",
      "name                                               object\n",
      "negativereason_gold                                object\n",
      "retweet_count                                       int64\n",
      "text                                               object\n",
      "tweet_coord                                        object\n",
      "tweet_created                   datetime64[ns, UTC-08:00]\n",
      "tweet_location                                     object\n",
      "user_timezone                                      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 1. Missing Values\n",
    "print(\"=== MISSING VALUES (RAW DATASET) ===\\n\")\n",
    "missing_raw = df_raw.isnull().sum()\n",
    "print(missing_raw[missing_raw > 0])\n",
    "\n",
    "print(\"\\n=== MISSING VALUES (INCREMENTAL DATASET) ===\\n\")\n",
    "missing_incremental = df_incremental.isnull().sum()\n",
    "print(missing_incremental[missing_incremental > 0])\n",
    "\n",
    "# 2. Duplicate Records\n",
    "print(\"\\n=== DUPLICATE RECORDS ===\")\n",
    "duplicates_raw = df_raw.duplicated().sum()\n",
    "duplicates_incremental = df_incremental.duplicated().sum()\n",
    "\n",
    "print(f\"Raw dataset duplicate records: {duplicates_raw}\")\n",
    "print(f\"Incremental dataset duplicate records: {duplicates_incremental}\")\n",
    "\n",
    "# 3. Data Type Validation (Quick Cross-Check)\n",
    "print(\"\\n=== DATA TYPE CONSISTENCY ===\")\n",
    "print(\"RAW dataset types:\\n\", df_raw.dtypes)\n",
    "print(\"\\nINCREMENTAL dataset types:\\n\", df_incremental.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861401ee",
   "metadata": {},
   "source": [
    "### Data Quality Checks Discussion\n",
    "\n",
    "#### (a) Missing Values\n",
    "Both datasets show missing values in several columns, reflecting the informal and user-generated nature of Twitter data:\n",
    "\n",
    "- **`negativereason`** and **`negativereason_confidence`** have null entries since not every tweet provides a complaint or reason for dissatisfaction.  \n",
    "- **`tweet_coord`**, **`tweet_location`**, and **`user_timezone`** are also partially missing .\n",
    "- **`airline_sentiment_gold`** and **`negativereason_gold`** are almost fully empty.\n",
    "\n",
    "#### (b) Duplicate Records\n",
    "Both datasets contain **36 duplicate rows**. These duplicates are likely due to:\n",
    "\n",
    "These duplicates will be removed during transformation.\n",
    "\n",
    "#### (c) Data Type Consistency\n",
    "All columns exhibit consistent data types across datasets:\n",
    "- **Categorical / textual:** stored as `object`\n",
    "- **Numerical:** stored as `float64` or `int64`\n",
    "- **Temporal:** `tweet_created` correctly parsed as `datetime64[ns]`\n",
    "\n",
    "I found no structural or type discrepancies, proving both datasets are now ready for the next validation step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cbc6e0",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Merging and Validating the Combined Dataset\n",
    "\n",
    "The next thing I did was to verify that both the **raw** and **incremental** datasets share a consistent structure and can be merged seamlessly if needed during transformation.\n",
    "\n",
    "This step validates:\n",
    "1. Column alignment â€” ensuring both datasets have identical structures.\n",
    "2. Row count expectations â€” confirming the merge produces the correct total records.\n",
    "3. Overlap and duplicates â€” identifying any repeated records across datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3674a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns only in raw dataset: set()\n",
      "Columns only in incremental dataset: set()\n",
      "\n",
      "Column structure is consistent across both datasets.\n",
      "\n",
      "Combined dataset shape: (16640, 15)\n",
      "Expected total records (before removing duplicates): 16640\n",
      "Total duplicate records after merge: 2036\n",
      "\n",
      " Merge validated â€” schema and structure are consistent.\n"
     ]
    }
   ],
   "source": [
    "# Compare column structures between the two datasets\n",
    "raw_columns = set(df_raw.columns)\n",
    "incremental_columns = set(df_incremental.columns)\n",
    "\n",
    "print(\"Columns only in raw dataset:\", raw_columns - incremental_columns)\n",
    "print(\"Columns only in incremental dataset:\", incremental_columns - raw_columns)\n",
    "\n",
    "if raw_columns == incremental_columns:\n",
    "    print(\"\\nColumn structure is consistent across both datasets.\\n\")\n",
    "else:\n",
    "    print(\"\\nColumn mismatch detected â€” review column alignment before transformation.\\n\")\n",
    "\n",
    "#  Validate the merge\n",
    "df_combined = pd.concat([df_raw, df_incremental], ignore_index=True)\n",
    "\n",
    "# Compute and display validation metrics\n",
    "expected_total = len(df_raw) + len(df_incremental)\n",
    "duplicates_after_merge = df_combined.duplicated().sum()\n",
    "\n",
    "print(f\"Combined dataset shape: {df_combined.shape}\")\n",
    "print(f\"Expected total records (before removing duplicates): {expected_total}\")\n",
    "print(f\"Total duplicate records after merge: {duplicates_after_merge}\")\n",
    "\n",
    "# Confirm readiness for transformation\n",
    "print(\"\\n Merge validated â€” schema and structure are consistent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf33f93",
   "metadata": {},
   "source": [
    "### Merge Validation Discussion\n",
    "\n",
    "The merge validation confirms that:\n",
    "- Both datasets share identical column structures and compatible data types.\n",
    "- The combined dataset shape aligns with expectations.\n",
    "- A higher duplicate count (2,036) arises due to overlap between the incremental subset and raw dataset, as expected since the incremental sample was derived from the latest 2,000 records.\n",
    "\n",
    "This confirms that both datasets are **schema-aligned**, **structurally consistent**, and **ready for transformation** in the next phase (`etl_transform.ipynb`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c0cf0",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Saving Validated Data for Transformation\n",
    "\n",
    "Having confirmed the structural integrity and schema alignment of both datasets, I now save the validated copies to the `data/` directory.  \n",
    "These files will serve as clean, ready-to-transform inputs for the next notebook (`etl_transform.ipynb`).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ac4aa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated raw dataset saved at: /Users/nathanomenge/Desktop/ET_Exam_Nathan_637/data/raw_data.csv\n",
      "Validated incremental dataset saved at: /Users/nathanomenge/Desktop/ET_Exam_Nathan_637/data/incremental_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Save validated datasets to the data folder\n",
    "raw_save_path = os.path.join(data_dir, \"raw_data.csv\")\n",
    "incremental_save_path = os.path.join(data_dir, \"incremental_data.csv\")\n",
    "\n",
    "df_raw.to_csv(raw_save_path, index=False)\n",
    "df_incremental.to_csv(incremental_save_path, index=False)\n",
    "\n",
    "print(f\"Validated raw dataset saved at: {raw_save_path}\")\n",
    "print(f\"Validated incremental dataset saved at: {incremental_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl_exam_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
